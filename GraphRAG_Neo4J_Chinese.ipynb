{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "5x3LkpUztHNU"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPIRSGz4tHNV",
        "outputId": "aef3b91c-bba8-4504-8210-c8f10ff3af11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import  RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from yfiles_jupyter_graphs import GraphWidget\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "import os\n",
        "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
        "from neo4j import  Driver\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "L0nXP1aYtHNW"
      },
      "outputs": [],
      "source": [
        "graph = Neo4jGraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "pXf7OTGHtHNW"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Step 1: Load Document\n",
        "loader = TextLoader(file_path=\"input/hetangyuese_zhuziqing_utf8.txt\")\n",
        "docs = loader.load()\n",
        "\n",
        "# Step 2: Split Document into Chunks (returns List[Document])\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=24)\n",
        "documents = text_splitter.split_documents(docs)  # This is already a list of Document objects\n",
        "\n",
        "# Step 3: Load LLMGraphTransformer\n",
        "#llm = OllamaFunctions(model=\"llama3.1\", temperature=0, format=\"json\")\n",
        "#llm_graph_transformer = LLMGraphTransformer.from_llm(\"meta-llama/Llama-3-8B\", device=\"mps\")  # Use Apple GPU if available\n",
        "llm=ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "llm_graph_transformer = LLMGraphTransformer(llm=llm)\n",
        "\n",
        "# Step 4: Convert the documents to graph documents\n",
        "graph_documents = llm_graph_transformer.convert_to_graph_documents(documents)\n",
        "\n",
        "# Step 5: Add the documents to the graph\n",
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    baseEntityLabel=True,\n",
        "    include_source=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjcAkzHBUXeA",
        "outputId": "977cd536-c73d-457f-fd14-d466f947d9a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GraphDocument(nodes=[Node(id='朱自清', type='Person', properties={}), Node(id='荷塘', type='Place', properties={}), Node(id='妻', type='Person', properties={}), Node(id='闰儿', type='Person', properties={}), Node(id='月亮', type='Object', properties={}), Node(id='杨柳', type='Object', properties={}), Node(id='树', type='Object', properties={}), Node(id='叶子', type='Object', properties={}), Node(id='花', type='Object', properties={}), Node(id='月光', type='Object', properties={})], relationships=[Relationship(source=Node(id='朱自清', type='Person', properties={}), target=Node(id='荷塘', type='Place', properties={}), type='THINK_ABOUT', properties={}), Relationship(source=Node(id='朱自清', type='Person', properties={}), target=Node(id='妻', type='Person', properties={}), type='HAS_RELATIONSHIP', properties={}), Relationship(source=Node(id='妻', type='Person', properties={}), target=Node(id='闰儿', type='Person', properties={}), type='HAS_RELATIONSHIP', properties={}), Relationship(source=Node(id='月亮', type='Object', properties={}), target=Node(id='荷塘', type='Place', properties={}), type='ILLUMINATES', properties={}), Relationship(source=Node(id='杨柳', type='Object', properties={}), target=Node(id='荷塘', type='Place', properties={}), type='LOCATED_AT', properties={}), Relationship(source=Node(id='树', type='Object', properties={}), target=Node(id='荷塘', type='Place', properties={}), type='LOCATED_AT', properties={}), Relationship(source=Node(id='叶子', type='Object', properties={}), target=Node(id='荷塘', type='Place', properties={}), type='COVER', properties={}), Relationship(source=Node(id='花', type='Object', properties={}), target=Node(id='荷塘', type='Place', properties={}), type='COVER', properties={}), Relationship(source=Node(id='月光', type='Object', properties={}), target=Node(id='荷塘', type='Place', properties={}), type='ILLUMINATES', properties={})], source=Document(metadata={'source': 'input/hetangyuese_zhuziqing_utf8.txt', 'id': '2738647a069fa637a3aab0dc7c32da6e'}, page_content='## 作者 朱自清 :\\n\\n这几天心里颇不宁静。今晚在院子里坐着乘凉，忽然想起日日 走过的荷塘，在这满月的光里，总该另有-番样子吧。月亮渐渐地 升高了，墙外马路上孩子们的欢笑，已经听不见了；妻在屋里拍着 闰儿，迷迷糊糊地哼着眠歌。我悄悄地披了大衫，带上门出去。\\n\\n沿着荷塘，是-条曲折的小煤屑路。这是-条幽僻的路；白天 也少人走，夜晚更加寂寞。荷塘四面，长着许多树，蓊蓊郁郁的。 路的-旁，是些杨柳，和-些不知道名字的树。没有月光的晚上， 这路上阴森森的，有些怕人。今晚却很好，虽然月光也还是淡淡 的。\\n\\n路上只我-个人，背着手踱着。这-片天地好像是我的；我也 像超出了平常的自己，到了另-世界里。我爱热闹，也爱冷静；爱 群居，也爱独处。像今晚上，-个人在这苍茫的月下，什么都可以 想，什么都可以不想，便觉是个自由的人。白天里-定要做的事， -定要说的话，现在都可不理。这是独处的妙处，我且受用这无边 的荷香月色好了。\\n\\n曲曲折折的荷塘上面，弥望的是田田的叶子。叶子出水很高， 像亭亭的舞女的裙。层层的叶子中间，零星地点缀着些白花，有袅 娜地开着的，有羞涩地打着朵儿的；正如-粒粒的明珠，又如碧天 里的星星，又如刚出浴的美人。微风过处，送来缕缕清香，仿佛远 处高楼上渺茫的歌声似的。这时候叶子与花也有-丝的颤动，像闪 电般，霎时传过荷塘的那边去了。叶子本是肩并肩密密地挨着，这 便宛然有了-道凝碧的波痕。叶子底下是脉脉的流水，遮住了，不 能见-些颜色；而叶子却更见风致了。\\n\\n月光如流水-般，静静地泻在这-片叶子和花上。薄薄的青雾 浮起在荷塘里。叶子和花仿佛在牛乳中洗过-样；又像笼着轻纱的 梦。虽然是满月，天上却有-层淡淡的云，所以不能朗照；但我以 为这恰是到了好处--酣眠固不可少，小睡也别有风味的。月光是\\n\\n隔了树照过来的，高处丛生的灌木，落下参差的斑驳的黑影，峭楞 楞如鬼-般；弯弯的杨柳的稀疏的倩影，却又像是画在荷叶上。塘 中的月色并不均匀；但光与影有着和谐的旋律，如梵婀玲上奏着的 名曲。'))"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "TnewOeCQSyS-"
      },
      "outputs": [],
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Load secrets\n",
        "import os\n",
        "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
        "NEO4J_USER = os.getenv(\"NEO4J_USER\")  # Default user unless changed\n",
        "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
        "\n",
        "# print(f\"NEO4J_URI: {NEO4J_URI}\")\n",
        "# print(f\"NEO4J_USER: {NEO4J_USER}\")\n",
        "# print(f\"NEO4J_PASSWORD: {NEO4J_PASSWORD}\")\n",
        "\n",
        "# Connect to Neo4j\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHbJPMfDtHNW"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.4' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/local/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#embeddings = OllamaEmbeddings(\n",
        "#    model=\"mxbai-embed-large\",\n",
        "#)\n",
        "\n",
        "#dimension=384\n",
        "#embeddings = OllamaEmbeddings(model=\"mxbai-embed-base\")\n",
        "#embeddings = OllamaEmbeddings(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "#embeddings = OllamaEmbeddings(model=\"all-minilm:l6-v2\")\n",
        "#!pip install -U sentence-transformers\n",
        "\n",
        "#from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "#embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=\"your_openai_api_key\")\n",
        "#embeddings = OpenAIEmbeddings(model=\"all-minilm:l6-v2\", openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "#embeddings = OllamaEmbeddings(model=\"all-minilm:l6-v2\", base_url=os.environ.get(\"OLLAMA_BASE_URL\"))\n",
        "#embeddings = OpenAIEmbeddings(model=\"all-MiniLM-L6-v2\", openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    embeddings,\n",
        "    search_type=\"hybrid\",\n",
        "    node_label=\"Document\",\n",
        "    text_node_properties=[\"text\"],\n",
        "    embedding_node_property=\"embedding\"\n",
        ")\n",
        "vector_retriever = vector_index.as_retriever()\n",
        "\n",
        "print(f\"type of vector_index = {type(vector_index)}, type of vector_retriever = type(vector_retriever)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "RMZlhtDmtHNW"
      },
      "outputs": [],
      "source": [
        "def create_fulltext_index(tx):\n",
        "    query = '''\n",
        "    CREATE FULLTEXT INDEX `fulltext_entity_id`\n",
        "    FOR (n:__Entity__)\n",
        "    ON EACH [n.id];\n",
        "    '''\n",
        "    tx.run(query)\n",
        "\n",
        "# Function to execute the query\n",
        "def create_index():\n",
        "    with driver.session() as session:\n",
        "        session.execute_write(create_fulltext_index)\n",
        "        print(\"Fulltext index created successfully.\")\n",
        "\n",
        "# Call the function to create the index\n",
        "# try:\n",
        "#     create_index()\n",
        "# except:\n",
        "#     pass\n",
        "\n",
        "# Close the driver connection\n",
        "driver.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yCMz_sRtHNW"
      },
      "outputs": [],
      "source": [
        "class Entities(BaseModel):\n",
        "    \"\"\"Identifying information about entities.\"\"\"\n",
        "\n",
        "    names: list[str] = Field(\n",
        "        ...,\n",
        "        description=\"All the person, organization, or business entities that \"\n",
        "        \"appear in the text\",\n",
        "    )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting organization and person entities from the text.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following \"\n",
        "            \"input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# prompt = \"\"\"请使用中文回答以下问题：\n",
        "# 问题: {question}\n",
        "# 答案:\n",
        "# \"\"\"\n",
        "\n",
        "entity_chain = llm.with_structured_output(Entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54H15KNAtHNX",
        "outputId": "7a984bb1-7b6c-4008-b210-96a9f028b742"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Entities(names=['文章作者'])"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entity_chain.invoke(\"文章作者是谁?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "dY8huoM8tHNX"
      },
      "outputs": [],
      "source": [
        "def generate_full_text_query(input: str) -> str:\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    if not words:\n",
        "        return \"\"\n",
        "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
        "    print(f\"Generated Query: {full_text_query}\")\n",
        "    return full_text_query.strip()\n",
        "\n",
        "\n",
        "# Fulltext index query\n",
        "def graph_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke(question)\n",
        "    for entity in entities.names:\n",
        "        response = graph.query(\n",
        "            \"\"\"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
        "            YIELD node,score\n",
        "            CALL {\n",
        "              WITH node\n",
        "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
        "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
        "              UNION ALL\n",
        "              WITH node\n",
        "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
        "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
        "            }\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": entity},\n",
        "        )\n",
        "        result += \"\\n\".join([el['output'] for el in response])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6fOJRPntHNX",
        "outputId": "855e31f9-381b-4944-cac1-28f454cf7fbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 116} for query: \"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(graph_retriever(\"文章作者是谁??\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "iCTMp3prtHNX"
      },
      "outputs": [],
      "source": [
        "def full_retriever(question: str):\n",
        "    graph_data = graph_retriever(question)\n",
        "    vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
        "    final_data = f\"\"\"Graph data:\n",
        "{graph_data}\n",
        "vector data:\n",
        "{\"#Document \". join(vector_data)}\n",
        "    \"\"\"\n",
        "    return final_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "Dzb2jcittHNY"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Use natural language and be concise.\n",
        "Answer:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "        {\n",
        "            \"context\": full_retriever,\n",
        "            \"question\": RunnablePassthrough(),\n",
        "        }\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "dtU0iMNgtHNY",
        "outputId": "a11c5ded-c80c-491a-c1b7-3248cb6a8405"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 116} for query: \"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'文章作者是朱自清。'"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(input=\"文章作者是谁?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "3DDd1wdEbj4n",
        "outputId": "fe2a14ed-bd8a-4770-c6ba-983d77ca9bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 116} for query: \"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'文章写于1927年。'"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# entity_chain.invoke(\"文章是哪一年写的?\")\n",
        "# graph_retriever(\"文章是哪一年写的?\")\n",
        "chain.invoke(input=\"文章是哪一年写的? 请使用中文回答\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "M8rG_Yx4by-g",
        "outputId": "9ff80d0f-34a7-400a-fc9d-aed0a06e022a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 116} for query: \"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 116} for query: \"CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'作者悄悄地披上大衫，带上门，沿着一条曲折的小煤屑路走到了荷塘。'"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(input=\"作者怎样来到荷塘的？\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
